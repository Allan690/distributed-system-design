{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Designing an API Rate Limiter\n",
    "\n",
    "An API reate limiter will throttle users based on the number of requests they are sending.\n",
    "\n",
    "## Why Rate Limiting?\n",
    "Rate limiting helps to protect services against abusive behaviors targeting the application such as Denial-of-service (DOS) attacks, brute-force password attempts, brute-force credit card transactions, etc.\n",
    "\n",
    "We also want to prevent revenue loss, to reduce infrastructure costs, stop spamming and stop online harassment. \n",
    "\n",
    "Here's some scenarios that show how benefitial it is to Rate limit our API/Service:\n",
    "\n",
    "- **Misbehaving clients:** Sometimes, clients can overwhelm servers by sending large number of requests, either intentionally or unintentionally. \n",
    "\n",
    "- **Security:** Limiting the number of times a user is allowed to try authenticating with a wrong password.\n",
    "\n",
    "- **Preventing abusive and bad design practices:** Without API limits, developers of client apps might request the same info over and over again.\n",
    "\n",
    "- **Revenue:**  Certain services might want to limit operations based on the tier of their customer's service and thus create a revenue model off the rate limiting. To go beyond the set limit, the user has to buy higher limits.\n",
    "\n",
    "- Prevent spikiness of traffic so that the service stays reliably up for all.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Requirements and System Goals\n",
    "\n",
    "#### Functional requirements\n",
    "1. Limit the number of requests an entity can send to an API within a time window\n",
    "2. The user should get an error whenever they cross the defined threshold within a single server or across a set of servers.\n",
    "\n",
    "#### Non-Functional requirements\n",
    "1. The system should be highly available, always protecting our API service from external attacks.\n",
    "2. The rate limiter should NOT introduce substantial latencies affecting the user experience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Throttling Types\n",
    "\n",
    "* ***Hard Throttling*** – Number of API requests cannot exceed the throttle limit\n",
    "\n",
    "* ***Soft Throttling*** – Set the API request limit to exceed by some percentage. E.g, if the rate-limit = 100 messages/minute, and 10% exceed-limit, our rate limiter will allow up to 110 messages per minute\n",
    "\n",
    "* ***Dynamic Throttling*** – The number of requests can exceed the limit if the system has some free resources available. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Algorithms used for Rate Limiting\n",
    "\n",
    "#### Fixed Window Algorithm\n",
    "Here, the time window is considered from the start of the time-unit to the end of the time-unit. For instance, a period will be considered 0-60 sec for a minute regardless of the time frame at which the API request has been made.\n",
    "\n",
    "The diagram below shows that we will only throttle 'm5' message, if our rate limit is 2 messages per second.\n",
    "\n",
    "![](images/fixed_rolling_window.svg)\n",
    "\n",
    "#### Rolling Window Algorithm\n",
    "Here, the time window is considered from the fraction of time at which the request is made plus the time window length.\n",
    "\n",
    "For example, if our rate limit = 2 msg per sec, the two messages sent at the 300th millisecond (m1) and 400th millisecond (m2), we'll count them as two messages starting from the 300th of that second to the 300th of the next second (making up one second).\n",
    "\n",
    "In the above diagram, we'll therefore throttle m3, m4.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. High Level Design\n",
    "\n",
    "Once a new request arrives, the Web server first asks the Rate Limiter to decide if it will be served or throttled. If the request is not throttled, the it's passed to the API servers. \n",
    "\n",
    "![](images/rate_limiter_high_level_design.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Basic System Design and Algorithm\n",
    "\n",
    "Assume our rate limiter allows 3 requests/sec per user. \n",
    "\n",
    "For each unique user, \n",
    "- Keep a count representing how many requests the user has made\n",
    "- and a timestamp when we started counting\n",
    "\n",
    "We can keep this in a hashtable, where:\n",
    "```python\n",
    "#  Key (userID): Value {count, start_time}\n",
    "hashtable = {\n",
    "    'userID0': {\n",
    "        'count': 3, 'start_time': 1574866492\n",
    "    },\n",
    "    'userId1': {\n",
    "        'count': 1, 'start_time': 1574873716\n",
    "    },\n",
    "    ...\n",
    "}\n",
    "```\n",
    "When a new request comes in, the rate limiter will perform the following steps:\n",
    "\n",
    "1. If the `userID` is not present in hash-table, \n",
    "    - insert it, \n",
    "    - set `count` to 1 and set `start_time` to current epoch time\n",
    "2. Otherwise, find the existing record of the userID, and \n",
    "    - if `current_time - start_time >= 1 min`, set the `start_time` to be the current time, \n",
    "    - set `count` to 1 and allow the request\n",
    "3. If `current_time - start_time <= 1 min` and\n",
    "    - If `count < 3`, increment the count and allow the request.\n",
    "    - If `count >= 3`, reject the request.\n",
    "    \n",
    "#### Problems with this Fixed Window Algorithm\n",
    "1. We are resetting the `start_time` at the end of every minute, which means we can potentially allow twice the number of requests per minute.\n",
    "\n",
    "Imagine if a user sends 3 requests at the last second of a minute, they can immediately send 3 more requests at the very first second of the next minute, resulting in 6 requests in a span of two seconds. The solution for this would be a sliding window algorithm.\n",
    "\n",
    "![](images/fixed_window_problem.svg)\n",
    "\n",
    "2. Atomicity: The read and then write process can create a race condition. Imagine, a given user's current count = 2. If two seperate processes served each of these requests and concurrently read the count before either updated it, each process would erroneously think that the user had one more request to go hit the rate limit. \n",
    "\n",
    "![](images/fixed_window_atomicity.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Slide Window Algorithm\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
