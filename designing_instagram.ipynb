{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Designing Instagram\n",
    "Let's design a photo-sharing service like IG, where users upload photos to share them with other users.\n",
    "\n",
    "Instagram enables its users to upload and share their photos and videos with other users. Users can choose to share information publicly or privately. Anything shared publicly can be seen by any other user, whereas privately shared content can only be accessed by a specified set of people.\n",
    "\n",
    "We plan to design a simpler version of Instagram, where a user can share photos and can also follow other users. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Requirements and Goals of the System\n",
    "\n",
    "#### Functional requirements\n",
    "1. Users should be able to upload/download/view photos\n",
    "2. Users can perform searches baed on photo/video titles\n",
    "3. Users can follow other users\n",
    "4. The system should generate Newsfeed consisting top photos from all the people the user follows\n",
    "\n",
    "#### Non-functional requirements\n",
    "1. The service needs to be highly available\n",
    "2. The acceptable latency is 200ms for News Feed generation\n",
    "3. The system should be highly reliable; any uploaded photo/video should never be lost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Capacity Estimation and Constraints\n",
    "The system would be read-heavy, so we'll focus on buiding a system that can retrieve photos quickly.\n",
    "\n",
    "- Assume we have 500M total users, with 1M daily active users.\n",
    "- 2M new photos every day, 23 new photos per secod.\n",
    "- Average photo file size ~= 200KB\n",
    "- Total space required for a 1 day of photos => \n",
    "    ```\n",
    "    2M * 200KB => 400GB\n",
    "    ```\n",
    "- Total space for 10 years:\n",
    "    ```\n",
    "    400GB * 365 days * 10 years ~= 1425 TB => 1.4 Petabytes\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. High Level System Design\n",
    "At a high-level, we need to support two scenarios: uploading photos and view/searching photos.\n",
    "\n",
    "We need object storage servers to store photos and also some DB servers to store metadata information about the photos\n",
    "\n",
    "![](images/instagram_high_level_design.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Database Schema\n",
    "> DB schema will help understand data flow among various components and later guid towards data partitioning.\n",
    "\n",
    "We need to store user data, their photos, and people they follow.\n",
    "Photo table \n",
    "\n",
    "\n",
    ">| Photo    |            \n",
    "| --- |             \n",
    "| PhotoID: int (PK) |     \n",
    "| UserID: int     |\n",
    "| PhotoLatitude: int |\n",
    "| PhotoLongitude: int |\n",
    "| UserLatitude: int |\n",
    "| UserLongitude: int |\n",
    "| CreationDate: datetime |\n",
    "\n",
    "\n",
    ">| User |\n",
    "| --- |\n",
    "| UserID: int (PK) |\n",
    "| Name: varchar(20) |\n",
    "| DOB: datetime |\n",
    "| CreatedAt: datetime |\n",
    "| LastLogin: datetime |\n",
    "\n",
    ">|UserFollow |  |\n",
    "|---|---|\n",
    "| PK | UserID1: int |\n",
    "| PK | UserID2: int|\n",
    "\n",
    "\n",
    "We could use an RDBMS like MySQL since we require joins. But relational DB come with their challenges, especially when we need to scale them. So we'll store the schema in a distributed wide-column NoSQL datastore like [Cassandra](https://en.wikipedia.org/wiki/Apache_Cassandra).\n",
    "All the photo metadata can go to a table where the 'key' is the `PhotoID` and the 'value' would be an object containing Photo related details.\n",
    "Cassandra or key-value stores in general always maintain a certain number of replicas to offer reliability. Also in such data stores, deletes don't get applied instantly, data is retained for a few days to support undeleting, before getting removed permanently.\n",
    "\n",
    "We can store the actual photos in as distributed file storage like [Hadoop](https://en.wikipedia.org/wiki/Apache_Hadoop) or [S3](https://en.wikipedia.org/wiki/Amazon_S3).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Size Estimation\n",
    "\n",
    "Let's estimate how much storage we'll need for the next 10 years.\n",
    "\n",
    "### User\n",
    "Assuming each int and datetime is 4 bytes, each row in User table will have:\n",
    "```\n",
    "UserID(4) + Name(20 bytes) + Email(32 bytes) + DOB(4 bytes) + \n",
    "CreatedAt(4) + LastLogin(4) = 68 bytes\n",
    "```\n",
    "We have 500 million users:\n",
    "```\n",
    "500 million * 68 ~= 32 GB\n",
    "```\n",
    "\n",
    "### Photo\n",
    "Each row in Photos table will have:\n",
    "```\n",
    "PhotoID (4 bytes) + UserID (4 bytes) + PhotoPath (256 bytes) + PhotoLatitude (4 bytes) + PhotLongitude(4 bytes) + UserLatitude (4 bytes) + UserLongitude (4 bytes) + CreationAt (4 bytes) = 284 bytes\n",
    "```\n",
    "We get 2M photos every day, so for one day we need:\n",
    "```\n",
    "2 M * 284 bytes ~= 0.5 GB per day\n",
    "\n",
    "For 10 years we'll need:\n",
    "0.5GB per day * 365 days * 10 years => 1.88 TB\n",
    "```\n",
    "\n",
    "### UserFollow\n",
    "Each row will have 8 bytes. Assume on average, each user follows 500 users, We would need 1.82 TB of storage for the UserFollow Table:\n",
    "```\n",
    "8 bytes * 500 followers * 500M users ~= 1.82 TB\n",
    "```\n",
    "Total space required for the DB tables will be:\n",
    "```\n",
    "32 GB + 1.88 + 1.82  ~= 3.7TB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Component Design\n",
    "Photo uploads (or writes) can be slow as they have to go to the disk, while reads will be faster, especially if they are being served from cache.\n",
    "\n",
    "Uploading users can consume all available connections, as uploading is a slow process, meaning reads can't be served if the system gets busy with all the write requests. We should keep in mind that all web servers have a connection limit. If we assume that a web server can have a maximum of 500 connections at any time, then it ca't have more than 500 concurrent reads and uploads. To handle this bottleneck, we can split reads and writes into seperate services. We'll have dedicated servers for reads and different servers for uploads to ensure uploads don't hog the system.\n",
    "\n",
    "> Also, separating reads from writes will allow us to scale and optimize each operation independently.\n",
    "\n",
    "![](images/ig_read_writes.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Reliability and Redundancy\n",
    "Losing files is not an option for our service. \n",
    "\n",
    "We'll store multiple copies of each file so that if one storage server dies, we can retrieve another copy on a different storage server.\n",
    "\n",
    "This principle also applies to the rest of the system. IF we want high availability, we need to have multiple replicas of services running, so that if a few services go down, the system remains available and running. \n",
    "\n",
    "> Redundancy removes the single point of failure in the system, taking control after a failover.\n",
    "\n",
    "If there are two instances of the same service running on production and one fails, the system can failover to the healthy copy. Failover can happen automatically or be done manually.\n",
    "\n",
    "![](images/ig_redundancy.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
